Based on papers \cite{holden2006convergence} and \cite{dahlby2007geometric} we have implemented a finite difference scheme with periodic boundary conditions for which convergence can be verified numerically when the analytic solutions of the input data are known. Furthermore, for other classes of initial conditions where we do not have an analytical solution, the scheme seems to behave in a way that is largely consistent with the literature on the equation. 

A lot of time was spent investigating ways to analyze the convergence of the scheme analytically in a way that is within the scope of this course, but it appears that more advanced theory is required for the proof. We settled on proving consistency and presenting a possible stepping stone for an alternative proof to that of Holden and Raynaud which utilizes the fact that the scheme can be described completely by a single - though complicated - matrix. We leave it an open question whether it is possible to analyze this matrix analytically. 

During the course of the project, we discovered an interesting and for us inexplicable effect. The forward Euler method in time gave superior results to that of higher order integrators, and it seemed to converge to the solutions offered by the higher order integrators as the time step was reduced and spatial step fixed. This is likely connected with the observations that smaller time steps resulted in greater errors, atleast up to a point where they stabilized. We have been unable to give a proper explanation for this phenomenon, and it may thus warrant further studies.

Finally, we discussed our experiences with the implementation. By profiling our code to figure out the main bottlenecks, we reduced both the computational time and complexity of our code significantly. In particular, the Fourier transformation suggested by Holden and Raynaud brought an immense improvement in computational efficiency compared to solvng the linear system. To put computational speed into perspective, we measured the algorithm to generate $100 \text{MB}$ of data per second(or equivalently roughly 12 million grid points per second) on an ordinary computer, which quickly places memory as the main restriction rather than computational speed when running simulations. We stress that our method has fairly little overhead in terms of memory - the large memory usage is simply a consequence of storing the computational results. We also briefly discussed how the memory usage issue for very high-resolution simulations can be circumvented by way of \emph{piecewise compression}, which is the term we have coined for the method of running multiple dependent subsequent simulations and downsampling the results on-the-fly.

Finally, as is required, we are obliged to discuss our experiences with working as a team. Like a band of brothers, we have eaten together, laughed together, cried together and worked together, plunging onward into the darkness like a ship without a sail, trying to stay afloat as we crashed into rocks and debris, emerging shipwrecked and without a sense of direction as we were finally carried by a peakon onto the shores of enlightenment and understanding. Summarized in a slightly less dramatic way, we have worked together at nearly all times, sharing responsibilities equally amongst ourselves and checking each other's work. The project as a whole has been a challenging, yet rewarding experience, and working as a team has been an exclusively positive experience.