\subsection*{Invertibility of $\bm{A}$}
Since the scheme depends on transformation back and forth between $m$ and $u$, it is crucial that the linear operator $A$ is invertible. Its invertibility can be shown in a few simple steps. First, note that $A$ can be written in circular matrix form
\begin{align*}
\bm{A} = 
\begin{pmatrix}
  (1 + \frac{2}{h^2}) & -\frac{1}{h^2} &  & -\frac{1}{h^2} \\
  -\frac{1}{h^2} & \ddots & \ddots  &  & &   \\
  & \ddots & \ddots & -\frac{1}{h^2}\\
  -\frac{1}{h^2} & & -\frac{1}{h^2} & (1 + \frac{2}{h^2})
 \end{pmatrix}.
\end{align*}

Then it is fairly easy to see that $A$ is diagonally dominant, since
\begin{align*}
|1 + \frac{2}{h^2}| = 1 + \frac{2}{h}> |-\frac{1}{h^2}| + |-\frac{1}{h^2}| = \frac{2}{h^2}.
\end{align*}

Since a diagonally dominant matrix is non-singular, $A$ is invertible.

\subsection*{Convergence of Holden Raynaud}
Helge Holden and Xavier Raynaud proved the convergence of their finite difference scheme \cite{holden2006convergence}, under the assumption that $u_{0} - u_{0}'' \geq 0$ for initial data $u_{0} \in H^{1}([0,1])$. This proof is far beyond the scope of our course, so only an outline of the proof will be provided. \\

First, it is shown that if $m_{i}(0) \geq 0 \; \forall \;i$, then any solution $u(t)$ will have $m_{i}(t) \geq 0 \; \forall \;i $. Further, a uniform bound on the $H^{1}$ norm of the sequence $u^{n}$ in [0,T] is established. This also guarantees the existence of solutions in [0,T] for any given $T > 0$, since $\text{max}_{i}|u_{i}^{n}(t)| = \|u^{n}(\cdot,t)\|_{L^{\infty}} \leq \mathcal{O}(1) \|u^{n}\|_{H^{1}}$ remains bounded.

After this, it is shown that $u_{x}^{n}$ and $u_{t}^{n}$ are bounded in $L^{2}([0,1])$, and that $u_{x}^{n}$ has a uniformly bounded total variation. This is enough to prove that one can extract a converging subsequence of $u^{n}$, and that the limit is a solution of the Camassa-Holm equation. 

This however, is far beyond the scope of this project, so we begin by proving consistency of our method.

\subsection*{Consistency}
We only prove consistency for the original scheme in equation (\ref{eq:discretized}), but the proof should be similar for the modified scheme as well. With the difference operators as defined in equation (\ref{eq:operators}) we get that:

\begin{align*}
D_- D_+ \left( U_j^n \right)  &= \frac{\partial^2}{\partial x^2} (u) + \mathcal{O} \left( h^ 2 \right), \\
 D_- \left(M_j^n U_j^n \right) &= m \left( \frac{\partial}{\partial x} (u) + \mathcal{O}(h) \right) + u \left( \frac{\partial}{\partial x} (m) + \mathcal{O} \left( h \right) \right),  \\
D \left(U_j^n \right) &= \frac{\partial}{\partial x} (u) + \mathcal{O} \left( h^2 \right).
\end{align*}

We use forward Euler to integrate:
\begin{align*}
D_+ (m) =  \frac{\partial}{\partial t} (m) + \mathcal{O}(k).
\end{align*}

Putting this back into equation (\ref{eq:discretized})

\begin{align*}
m &= u - \left( u_{xx} + \mathcal{O}\left(h^2\right) \right) \\
m_t  + \mathcal{O}(k) &= - \left( m \left( u_x + \mathcal{O}(h) \right) +  u \left( m_x + \mathcal{O}(h) \right)  \right) - m \left( u_x + \mathcal{O}(h) \right).
\end{align*}

Letting the time step and space step go to zero, we have
\begin{align*}
m &= u - u_{xx} \\
m_t &= - 2m u_x - u m_x,
\end{align*}
which is equal to equation (\ref{eq:CHhamiltonian}), so our scheme is consistent. 

\subsection*{Stability}
The finite difference scheme can be summarized in matrix form in the following way:
Define $\bm{B}$ as the backwards difference matrix operator, $\bm{F}$ as the forwards difference operator and $\bm{C}$ as the mean of $\bm{B}$ and $\bm{F}$. Furthermore, define $\bm{A}$ as the transformation to go from $\bm{u}$ to $\bm{m}$, ie:
\begin{align*}
\bm{m} = \bm{u}-D_-D_+\bm{u} = (\bm{I}-\bm{BF})\bm{u} = \bm{A} \bm{u}
\end{align*} 


We can rewrite the system as:
\begin{align*}
\bm{m} &= \bm{Au} \\
\bm{m}_t &= -\bm{BMu} - \bm{MCu} = \bm{-Qu},
\end{align*}

with $\bm{M}$ a diagonal matrix with elements from $\bm{m}$. When we also do the integration and the inverse $\bm{A}$ we get
\begin{align*}
\bm{m}^{n+1} &= \bm{m} + k\bm{m}_t \\
\bm{m}^{n+1} &= \bm{m} + k\bm{Qu} \\
\bm{u}^{n+1} &= \bm{A^{-1}m^{n+1}} = \left(\bm{I} -\bm{A^{-1}}k\bm{Q}\right)\bm{u} = \bm{Zu}.
\end{align*}
To have stability we may try to bound either the spectral radius the matrix norm by 1. However, this proved to be quite difficult and well beyond our scope, mainly because the $\bm{Q}$ matrix is dependent upon $\bm{m}$ (and then $\bm{u})$. Furthermore, the inverse of the tridiagonal (with corners) matrix $\bm{A}$ doesn't have an easy analytical solution. This also ruins any attempts of applying Gershgorin's theorem.

\subsection*{von Neumann's stability criterion}
An attempt at von Neumann's stability analysis was made, despite the fact that the procedure is primarily for finite difference schemes applied to linear partial differential equations. We define $U_{j}^{n} = g^{n}e^{i\theta j}$. For von Neumann stability, the desired inequality is
\begin{align}
|g| \leq 1 + \mu k,
\end{align}
where $\mu \geq 0$ is a constant. 
The inequality produced by von Neumann stability analysis was
\begin{align}
g \leq 1+ \frac{k}{h} g^{n}e^{i\theta j}\left[\frac{2-2e^{-2i\theta}+ e^{i\theta} - e^{-i\theta}}{2}\right],
\end{align}
which is clearly dependent on $h$. This makes von Neumann stability analysis inapplicable for our finite difference scheme.

