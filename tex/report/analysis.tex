\subsection*{Convergence of Holden Raynaud}
Helge Holden and Xavier Raynaud proved the convergence of their finite difference scheme in their article, under the assumption that $u_{0} - u_{0}'' \geq 0$ for initial data $u_{0} \in H^{1}([0,1])$. This proof is far beyond the scope of our course, so only an outline of the proof will be provided. \\

First, it is shown that if $m_{i}(0) \geq 0 \; \forall \;i$, then any solution $u(t)$ will have $m_{i}(t) \geq 0 \; \forall \;i $. Further, a uniform bound on the $H^{1}$ norm of the sequence $u^{n}$ in [0,T] is established. This also guarantees the existence of solutions in [0,T] for any given $T > 0$, since $\text{max}_{i}|u_{i}^{n}(t)| = \|u^{n}(\cdot,t)\|_{L^{\infty}} \leq \mathcal{O}(1) \|u^{n}\|_{H^{1}}$ remains bounded.

After this, it is shown that $u_{x}^{n}$ and $u_{t}^{n}$ are bounded in $L^{2}([0,1])$, and that $u_{x}^{n}$ has a uniformly bounded total variation. This is enough to prove that one can extract a converging subsequence of $u^{n}$, and that the limit is a solution of the Camassa-Holm equation. 

This however, is far beyond the scope of this project, so we begin by proving consistency of our method.

\subsection*{Consistency}
Our scheme is as following:
\begin{align}
m &= u - D_- D_+ u \notag \\
m_t &=- D_- ( m u ) - m D ( u ),
\label{eq:discretized}
\end{align}
where the operators are defined as in (\ref{eq:operators})

\begin{align*}
D_- D_+ \left( U_j^n \right)  &= \frac{\partial}{\partial x} (u) + \mathcal{O} \left( h^ 2 \right) \\
 D_- \left(M_j^n U_j^n \right) &= m \frac{\partial}{\partial x} (u) + u \frac{\partial}{\partial x} (m) + \mathcal{O} \left( h \right)  \\
D \left(U_j^n \right) &= \frac{\partial}{\partial x} (u) + \mathcal{O} \left( h^2 \right).
\end{align*}

If we also use forward Euler to integrate we get that
\begin{align*}
D_+ (m) =  \frac{\partial}{\partial t} (m) + \mathcal{O}(k).
\end{align*}

Putting this back into equation (\ref{eq:discretized}) we get

\begin{align*}
m &= u - \left( u_{xx} + \mathcal{O}\left(h^2\right) \right) \\
m_t  + \mathcal{O}(k) &= - \left( m u_x + u m_x + \mathcal{O}(h) \right) - m \left( u_x + \mathcal{O}(h) \right).
\end{align*}

Letting the timestep and spacestep go to zero, we get
\begin{align*}
m &= u - u_{xx} \\
m_t &= - m u_x - u m_x - m u_x = - 2m u_x - u m_x,
\end{align*}
which is equal to equation \ref{eq:CHhamiltonian}, so our scheme is consistent. If we should do the same analysis to the improved scheme 

\subsection*{Stability}
The finite difference scheme can be summarized in matrix form in the following way:
Define $\bm{B}$ as the backwards difference matrix operator, $\bm{F}$ as the forwards difference operator and $\bm{C}$ as the mean of $\bm{B}$ and $\bm{F}$. Furthermore, define $\bm{A}$ as the transformation to go from $\bm{u}$ to $\bm{m}$, ie:
\begin{align*}
\bm{m} = \bm{u}-D_-D_+\bm{u} = (\bm{I}-\bm{BF})\bm{u} = \bm{A} \bm{u}
\end{align*} 

We can rewrite the system as:
\begin{align*}
\bm{m} &= \bm{Au} \\
\bm{m}_t &= -\bm{BMu} - \bm{MCu} = \bm{-Qu},
\end{align*}

with $\bm{M}$ a diagonal matrix with elements from $\bm{m}$. When we also do the integration and the inverse $\bm{A}$ we get
\begin{align*}
\bm{m}^{n+1} &= \bm{m} + k\bm{m}_t \\
\bm{m}^{n+1} &= \bm{m} + k\bm{Qu} \\
\bm{u}^{n+1} &= \bm{A^{-1}m^{n+1}} = \left(\bm{I} -\bm{A^{-1}}k\bm{Q}\right)\bm{u} = \bm{Zu}.
\end{align*}
For us to have stability we may try to bound either the spectral radius or some matrix norm to be bounded by 1. However, this proved to be quite difficult and well beyond our scope, mainly because the $\bm{Q}$ matrix is dependent upon $\bm{m}$ (and then $\bm{u})$. Furthermore, the inverse of the tridiagonal (with corners) matrix $\bm{A}$ doesn't have an easy analytical solution. This also ruins any attempts of applying Gershgorin's theorem.


